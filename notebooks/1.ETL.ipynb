{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ETL\n",
    "\n",
    "\n",
    "In this notebook, the NY_taxi_data saved under the 'data' folder will be extracted and transfromed in an appropriate form to be loaded in a database. A Postgis database named 'cargo' was created inside a docker container in prior to this step (details on the setup for the docker environments is described in the README.md of this repository)\n",
    "\n",
    "The workflow I follow in this notebook is:\n",
    "\n",
    "1. Connect to the database (postgis)\n",
    "2. Create tables for each month's data ('taxi_jan', 'taxi_apr', 'taxi_jul')\n",
    "3. Convert the original text data and insert the values to the corresponding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/_compat.py:84: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation before connecting to the database\n",
    "\n",
    "* Prepare a list of all the NY_taxi_data file names available.\n",
    "* Separate the files depending on the corresponding month (Jan, Apr, Jul).\n",
    "    -> to distribute the data into different tables (due to limited memory space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/NY_taxi_data/yellow_tripdata_2015-01_00',\n",
       " '../data/NY_taxi_data/yellow_tripdata_2015-01_01',\n",
       " '../data/NY_taxi_data/yellow_tripdata_2015-01_02']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the names of NY taxi data and save them in a list\n",
    "filenames = sorted(glob.glob('../data/NY_taxi_data/*')) # in ascending order\n",
    "print(len(filenames))\n",
    "filenames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "27\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Separate Jan, Apr, Jul data\n",
    "Jan = []\n",
    "Apr = []\n",
    "Jul = []\n",
    "for i in range(len(filenames)):\n",
    "    if filenames[i][-5:-3] == '01':\n",
    "        Jan.append(filenames[i])\n",
    "    elif filenames[i][-5:-3] == '04':\n",
    "        Apr.append(filenames[i])\n",
    "    else:\n",
    "        Jul.append(filenames[i])\n",
    "\n",
    "print(len(Jan)) # list of data files from 2015-01\n",
    "print(len(Apr)) # 2015-04\n",
    "print(len(Jul)) # 2015-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to try connection to the database 'carto'\n",
    "# In case the connecting attempt fails, print the error message\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        #conn for connection\n",
    "        conn =  psycopg2.connect(dbname='carto', user='carto', password='carto', host='postgis', port='5432')\n",
    "    except psycopg2.DatabaseError:\n",
    "        print (\"I am unable to connect the database\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a table names to be created in the database\n",
    "tablenames = ['taxi_jan', 'taxi_apr', 'taxi_jul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a table called 'taxi_x' inside the postgis database\n",
    "def create_table(tablename):\n",
    "    # connect to the db\n",
    "    conn = connect_to_db()\n",
    "\n",
    "    # Prepare a query to create table for NY taxi data\n",
    "    q_create_table = f\"\"\"\n",
    "                    create table {tablename}\n",
    "                    (\n",
    "                        vendorID int,\n",
    "                        tpep_pickup_datetime timestamp,\n",
    "                        tpep_dropoff_datetime timestamp,\n",
    "                        passenger_count int,\n",
    "                        trip_distance numeric,\n",
    "                        pickup_longitude numeric,\n",
    "                        pickup_latitude numeric,\n",
    "                        RateCodeID int,\n",
    "                        store_and_fwd_flag char(1),\n",
    "                        dropoff_longitude numeric,\n",
    "                        dropoff_latitude numeric,\n",
    "                        payment_type int,\n",
    "                        fare_amount numeric,\n",
    "                        extra numeric,\n",
    "                        mta_tax numeric,\n",
    "                        tip_amount numeric,\n",
    "                        tolls_amount numeric,\n",
    "                        improvement_surcharge numeric,\n",
    "                        total_amount numeric\n",
    "                    )\n",
    "                    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()  # initiate cursor (communication with db)\n",
    "        cur.execute(q_create_table)  # execute the query\n",
    "        conn.commit()\n",
    "        print(f'{tablename} created')\n",
    "\n",
    "    except psycopg2.DatabaseError: # print error if fails\n",
    "        print (\"Failed to create the table\")\n",
    "\n",
    "    # Close the communication & connection with the postgis\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi_jan created\n",
      "taxi_apr created\n",
      "taxi_jul created\n"
     ]
    }
   ],
   "source": [
    "# Create tables for Jan, Apr, Jul\n",
    "for tablename in tablenames:\n",
    "    create_table(tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files, transform the data and load it to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fill the previously created tables\n",
    "def fill_table_with_data(filename, tablename):\n",
    "    # connect to the db\n",
    "    conn = connect_to_db()\n",
    "\n",
    "    # A query to insert data (row by row) to the table taxi\n",
    "    q_insert_data = f'''insert into {tablename}\n",
    "                    (\n",
    "                                vendorID,\n",
    "                                tpep_pickup_datetime,\n",
    "                                tpep_dropoff_datetime,\n",
    "                                passenger_count,\n",
    "                                trip_distance,\n",
    "                                pickup_longitude,\n",
    "                                pickup_latitude,\n",
    "                                RateCodeID,\n",
    "                                store_and_fwd_flag,\n",
    "                                dropoff_longitude,\n",
    "                                dropoff_latitude,\n",
    "                                payment_type,\n",
    "                                fare_amount,\n",
    "                                extra,\n",
    "                                mta_tax,\n",
    "                                tip_amount,\n",
    "                                tolls_amount,\n",
    "                                improvement_surcharge,\n",
    "                                total_amount\n",
    "                        )\n",
    "                        values (%s,%s,%s,%s,%s, %s,%s,%s,%s,%s, %s,%s,%s,%s,%s, %s,%s,%s,%s)'''\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        total = 0  # count how many rows are inserted\n",
    "        \n",
    "        with open(filename, 'r') as file:\n",
    "            # rows: a list of tuples\n",
    "            rows = [tuple(line.strip().split(',')) for line in file if line]\n",
    "            \n",
    "            # a row: a tuple of 19 string values\n",
    "            # Fill the table by inserting data row by row iteration\n",
    "            for row in rows:\n",
    "                \n",
    "                # Skip header if exists\n",
    "                if row[0].isalpha(): \n",
    "                    pass\n",
    "                \n",
    "                # Skip if no geo data\n",
    "                elif row[5:7] == ('0','0') or row[9:11] == ('0','0'): \n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    cur.execute(q_insert_data, row)\n",
    "                    total += 1\n",
    "\n",
    "            # All rows inserted -> commit the changes to the db\n",
    "            conn.commit()\n",
    "            print(f'{total} rows inserted out of {len(rows)}')\n",
    "\n",
    "    # Print error message if query fails\n",
    "    except psycopg2.DatabaseError:\n",
    "        print (\"Failed to copy data to the table\")\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "To insert data to the tables inside the db, a file was read line by line and itered, because lines with incorrect datatypes had to be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489619 rows inserted out of 500000\n",
      "489654 rows inserted out of 500000\n",
      "489574 rows inserted out of 500000\n",
      "489456 rows inserted out of 500000\n",
      "489867 rows inserted out of 500000\n",
      "489604 rows inserted out of 500000\n",
      "489581 rows inserted out of 500000\n",
      "489417 rows inserted out of 500000\n",
      "489577 rows inserted out of 500000\n",
      "489493 rows inserted out of 500000\n",
      "489664 rows inserted out of 500000\n",
      "489508 rows inserted out of 500000\n",
      "489887 rows inserted out of 500000\n",
      "489905 rows inserted out of 500000\n",
      "489556 rows inserted out of 500000\n",
      "489652 rows inserted out of 500000\n",
      "489618 rows inserted out of 500000\n",
      "489624 rows inserted out of 500000\n",
      "489529 rows inserted out of 500000\n",
      "489676 rows inserted out of 500000\n",
      "489647 rows inserted out of 500000\n",
      "489721 rows inserted out of 500000\n",
      "489660 rows inserted out of 500000\n",
      "489608 rows inserted out of 500000\n",
      "489424 rows inserted out of 500000\n",
      "243813 rows inserted out of 248987\n"
     ]
    }
   ],
   "source": [
    "# Use the function to fill the 'taxi_jan' table\n",
    "for i in range(len(Jan)):\n",
    "    fill_table_with_data(Jan[i], 'taxi_jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490624 rows inserted out of 500000\n",
      "490729 rows inserted out of 500000\n",
      "490839 rows inserted out of 500000\n",
      "490676 rows inserted out of 500000\n",
      "490739 rows inserted out of 500000\n",
      "490844 rows inserted out of 500000\n",
      "490963 rows inserted out of 500000\n",
      "490871 rows inserted out of 500000\n",
      "490740 rows inserted out of 500000\n",
      "490836 rows inserted out of 500000\n",
      "490870 rows inserted out of 500000\n",
      "490717 rows inserted out of 500000\n",
      "490856 rows inserted out of 500000\n",
      "490639 rows inserted out of 500000\n",
      "490806 rows inserted out of 500000\n",
      "490667 rows inserted out of 500000\n",
      "490719 rows inserted out of 500000\n",
      "490925 rows inserted out of 500000\n",
      "490799 rows inserted out of 500000\n",
      "490681 rows inserted out of 500000\n",
      "490700 rows inserted out of 500000\n",
      "490798 rows inserted out of 500000\n",
      "490891 rows inserted out of 500000\n",
      "490781 rows inserted out of 500000\n",
      "490679 rows inserted out of 500000\n",
      "490704 rows inserted out of 500000\n",
      "70505 rows inserted out of 71790\n"
     ]
    }
   ],
   "source": [
    "# Load all the NY taxi data from 2015-Apr to the database\n",
    "for i in range(len(Apr)):\n",
    "    fill_table_with_data(Apr[i], 'taxi_apr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492271 rows inserted out of 500000\n",
      "492293 rows inserted out of 500000\n",
      "492249 rows inserted out of 500000\n",
      "492168 rows inserted out of 500000\n",
      "492148 rows inserted out of 500000\n",
      "492519 rows inserted out of 500000\n",
      "492174 rows inserted out of 500000\n",
      "491991 rows inserted out of 500000\n",
      "492203 rows inserted out of 500000\n",
      "492355 rows inserted out of 500000\n",
      "492647 rows inserted out of 500000\n",
      "492037 rows inserted out of 500000\n",
      "492405 rows inserted out of 500000\n",
      "492104 rows inserted out of 500000\n",
      "492033 rows inserted out of 500000\n",
      "492356 rows inserted out of 500000\n",
      "492418 rows inserted out of 500000\n",
      "492063 rows inserted out of 500000\n",
      "492692 rows inserted out of 500000\n",
      "492394 rows inserted out of 500000\n",
      "492548 rows inserted out of 500000\n",
      "492169 rows inserted out of 500000\n",
      "490694 rows inserted out of 500000\n",
      "61091 rows inserted out of 62784\n"
     ]
    }
   ],
   "source": [
    "# Load all the NY taxi data from 2015-Jul to the database\n",
    "for i in range(len(Jul)):\n",
    "    fill_table_with_data(Jul[i], 'taxi_jul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More data: GeoJSON to PostGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step (notebook 2.EDA+model), the NY_taxi data will be queried to be read as a GeoDataFrame. To query the data more efficiently, I would like to include spatial join such as 'ST_Contains' in the query. In order to use this method, another geometric attribute - 'Polygons' of census blocks - should be present in the same database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:4326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360050001001</td>\n",
       "      <td>POLYGON ((-73.89277 40.79284, -73.89261 40.792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360050002001</td>\n",
       "      <td>POLYGON ((-73.86285 40.81267, -73.86191 40.812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360050002002</td>\n",
       "      <td>POLYGON ((-73.86708 40.81444, -73.86332 40.812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360050002003</td>\n",
       "      <td>POLYGON ((-73.85856 40.80665, -73.85848 40.806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360050004001</td>\n",
       "      <td>POLYGON ((-73.85972 40.81527, -73.85956 40.815...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          geoid                                           geometry\n",
       "0  360050001001  POLYGON ((-73.89277 40.79284, -73.89261 40.792...\n",
       "1  360050002001  POLYGON ((-73.86285 40.81267, -73.86191 40.812...\n",
       "2  360050002002  POLYGON ((-73.86708 40.81444, -73.86332 40.812...\n",
       "3  360050002003  POLYGON ((-73.85856 40.80665, -73.85848 40.806...\n",
       "4  360050004001  POLYGON ((-73.85972 40.81527, -73.85956 40.815..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read NYC census block group geometries file as a table\n",
    "census = gpd.read_file('../data/nyc_cbg_geoms.geojson')\n",
    "print(census.crs)\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/geodataframe.py:830: UserWarning: Geometry column does not contain geometry.\n",
      "  warnings.warn(\"Geometry column does not contain geometry.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "geoid       object\n",
       "geometry    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GeoAlchemy's WKTElement to create a geometric attribute with SRID\n",
    "def create_wkt_element(geom):\n",
    "    return WKTElement(geom.wkt, srid=4326)\n",
    "\n",
    "# Convert the geometry column type as object (if not, data cannot be queried)\n",
    "census['geometry'] = census['geometry'].apply(create_wkt_element)\n",
    "census.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare db (create a new table for the census data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_blocks created\n"
     ]
    }
   ],
   "source": [
    "# Create a table called census_blocks inside the postgis database\n",
    "def create_census_block_table(tablename):\n",
    "    # connect to the db\n",
    "    conn = connect_to_db()\n",
    "\n",
    "    # Prepare a query to create table for census_blocks\n",
    "    q_create_table = f\"\"\"\n",
    "                    create table {tablename}\n",
    "                    (\n",
    "                        geoid int,\n",
    "                        geometry geometry(Polygon,4326)\n",
    "                    )\n",
    "                    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()  # initiate cursor (communication with db)\n",
    "        cur.execute(q_create_table)  # execute the query\n",
    "        conn.commit()\n",
    "        print(f'{tablename} created')\n",
    "\n",
    "    except psycopg2.DatabaseError:\n",
    "        print (\"Failed to create the table\")\n",
    "\n",
    "    # Close the communication & connection with the postgis\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close ()\n",
    "        \n",
    "create_census_block_table('census_blocks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the file, transform the data and load it to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created\n",
      "Connected to the db\n",
      "Table created\n",
      "Data type converted succesfully\n",
      "Connection to the database closed\n"
     ]
    }
   ],
   "source": [
    "# Create SQL connection engine\n",
    "engine = create_engine('postgresql://carto:carto@postgis:5432/carto')\n",
    "print('Engine created')\n",
    "\n",
    "# Connect to database using a context manager\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    print('Connected to the db')\n",
    "    census.to_sql('census_blocks',\n",
    "                  engine,\n",
    "                  if_exists='replace',\n",
    "                  index=False,\n",
    "                  dtype={'geometry':Geometry})\n",
    "    \n",
    "    print('Table created')\n",
    "    \n",
    "    # Convert the geometry column back to Geometry datatype from string\n",
    "    sql = \"\"\"ALTER TABLE census_blocks\n",
    "             ALTER COLUMN geometry TYPE Geometry\n",
    "             USING ST_SetSRID(geometry::Geometry, 4326)\"\"\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    print('Data type converted succesfully')\n",
    "    \n",
    "conn.close()\n",
    "print('Connection to the database closed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "1. Data from Jan, Apr, Jul 2015 were loaded to a Postgis database. Their geometric attributes were not correctly assigned with their corresponding data type yet.\n",
    "\n",
    "\n",
    "2. Census block geometries were also loaded to the same databse for furture spatial queries.\n",
    "\n",
    "\n",
    "**3. How can this process be scaled for larger data?**\n",
    "\n",
    "One can create more tables partitioned by time. For instance, by day, so there be tables for every day's taxi trips. As a way to handle the given data, I already performed a partition by month.\n",
    "    \n",
    "Another way is to process the incoming data incrementally. For example, the function I programmed takes data month by month. Therefore, in case there is more upcoming data, I don't need to reprocess the previous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of basic ETL\n",
    "\n",
    "-----------------------------------------------------------\n",
    "\n",
    "## Next step: EDA and Train a baseline model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
